---
layout: post
title: "How MOSS Works"
date: 2019-05-03
---

With the ease of sharing and copying files over the internet, plagiarism has become a major problem in today’s education system and software solutions are becoming increasingly necessary to help detect plagiarism. MOSS is a copy-detection system that has proven to be very successful at plagiarism detection in source code. In this post, I will give an overview of copy-detection, document fingerprinting, and the winnowing algorithm used by MOSS. Then I will discuss the implementation and use of MOSS, and the effectiveness of an OCaml implementation of MOSS called OCaMOSS (my final project for CS 3110). 

_Note: This post is based on [Winnowing: Local Algorithms for Document Fingerprinting](http://theory.stanford.edu/~aiken/publications/papers/sigmod03.pdf) and the [writeup for OCaMOSS](https://github.com/RobYang1024/OCaMOSS/blob/master/3110%20Final%20Project%20Writeup.pdf). All figures are borrowed from those 2 papers._

## Background
Given a corpus of documents, a **copy-detection algorithm** identifies pairs of documents which are likely to have copied from each other. There are three properties that are required in effective copy-detection algorithms. 

1. **Whitespace insensitivity** - The algorithm must be able to ignore meaningless syntax like whitespace. For source-code plagiarism detection, the algorithm must also be unaffected by renaming identifiers. 
2. **Noise Suppression** - The discovered matches must be of sufficient length to be significant and interesting - for example, flagging a single matching word would not be a meaningful result.
3. **Position independence** - The position of the matching segments in each document should not affect the number of matches discovered. This means that reordering large blocks of the document should have no effect on the algorithm. 

Beyond these main requirements, other desired features include fast runtime when operating on large corpuses/long documents, and a low rate of false-positives (which noise insensitivity helps reduce).

**Document fingerprinting** is a common technique for copy-detection that avoids having to naively compare every substring of every document with every substring of every other document. Instead, a set of hashes (fingerprint) is precomputed for each document, and comparisons are made between the fingerprints of each document, which drastically reduces the total number of comparisons. 

The process of applying document fingerprinting in plagiarism detection can be described in four steps. 

1. Preprocess the document to remove irrelevant features like whitespace and identifiers.
2. Generate a sequence of hashes of the k-grams of the preprocessed document (the selection of k varies depending on the specific technique). 
3. Select a subset of hashes to use as document’s fingerprints. This step is interesting because which fingerprints are selected in each document will directly affect the number of matches discovered. 
4. Pairs of documents with a high number of matching fingerprints are flagged for review.

## Winnowing Algorithm
Winnowing is an algorithm for selecting the set of hashes to serve as the fingerprints of a document. At a high level, the algorithm applies sliding window of size w to the list of hashes. At each step, the algorithm records the rightmost minimum value in the window (if it has not been recorded already). When the window reaches the end of the sequence of hashes, the recorded set of hashes is taken as the fingerprints of the document.

Below is an example of document fingerprinting on a short example text, with the winnowing algorithm highlighted in steps d-f.

<p align="center">
  <img height="600" src="https://yangdanny97.github.io/misc/moss/fig1.png">
</p>

The winnowing algorithm results in fingerprints with several very useful properties (for detailed proofs, please see the winnowing paper). Using k-grams and a window size w, the following properties will hold:

- No matches shorter than k detected - this is due to the algorithm hashing substrings of length k, which means matching segments must be at least length k to be hashed to the same value.
- Guaranteed to select at least one hash per window-length - this is due to the sliding window; by the time the window has shifted one window length, the previous lowest hash must have moved out of the window and thus the algorithm is forced to select a new lowest hash from within the current window. This property is useful because it ensures that no part of the document will be omitted from the set of fingerprints.
- The two above properties ensure a third property: Matches of at least length w + k - 1 always detected. 

## Tests
The winnowing algorithm was tested on a corpus of web pages using hashes of 50-grams and a window size of 100, the results of which are included and summarized below. 

<p align="center">
  <img width="400" src="https://yangdanny97.github.io/misc/moss/fig2.png">
</p>

The winnowing algorithm selects a similar number of fingerprints and has similar density to the naive selection, but the fingerprints are much more evenly distributed throughout the document. The naive algorithm resulted in a maximum run of 29983 characters without any fingerprint selected, while the winnowing algorithm guarantees that at least one fingerprint is selected every 100 characters.

<p align="center">
  <img width="500" src="https://yangdanny97.github.io/misc/moss/fig3.png">
</p>

The frequency distribution of hashes roughly follows the power rule, which means that the words in the selected fingerprints are similar to the distribution of words in the source text. Common sequences of words will result in some hash values being more common, and this is reflected here.

## MOSS

MOSS (short for Measure of Software Similarity) is a system developed at Stanford that has made use of the winnowing algorithm to perform copy-detection for coding assignments. It uses a more robust winnowing algorithm that selects fewer fingerprints, which will not be discussed here but is described in slightly more detail in the original paper. 

There are two main components to MOSS. The first is a front-end that is language-specific that prepares each document by removing whitespace, identifiers, identifying keywords specific to that language. The document is then input into the fingerprinting engine, which operates with no knowledge of the type of the original documents. 

Fingerprints are tagged with their position in the original source code in order to display matching sections to the user. Additionally, instructors can specify a document of boilerplate code in the corpus, and MOSS will ignore hashes that match those of the boilerplate. The authors report that in practice MOSS has been effective at both detecting plagiarism and reducing plagiarism in classes, and that there have been no false-positives caused by the algorithm itself.

## OCaMOSS

In spring of 2018 we built an implementation the winnowing algorithm in OCaml and used it in a plagiarism detection system called OCaMOSS. We performed tests on several datasets of source code plagiarism and tested for both speed and correctness. 

<p align="center">
  <img width="500" src="https://yangdanny97.github.io/misc/moss/fig4.png">
</p>

Fig 4. (borrowed from OCaMOSS writeup) The results of testing OCaMOSS on the MiniFactorial corpus created by NordicWay. The test corpus contains 4 types of plagiarism: 
- type 1 refers to changing whitespace, layout, and comments
- type 2 refers to changing types, identifiers, and literals
- type 3 refers to reordering, adding, or removing statements
- type 4 refers to refactoring the code to use different syntactic variants

The system achieved the goal of having no false-positives, while still maintaining a high recall among most of the classes. The misclassification of some type-3 examples is probably due to the nature of the test corpus (programs are extremely short, and thus certain reorderings will affect every hash that is generated from the document). The misclassification of type-4 examples is due to the nature of type-4 plagiarism: if a student refactors the copied code heavily to make use of different syntactic variants (breaking up loops, using while loops instead of for loops, etc), the code becomes structurally different and is indistinguishable from a student’s original work. Thus, the misclassifications here are likely caused by our reluctance to generate false-positives, as well as heavily-refactored copied code being indistinguishable from a student’s original code.
